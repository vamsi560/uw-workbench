# Docker Compose for LLM Microservice Development
version: '3.8'

services:
  llm-service:
    build:
      context: .
      dockerfile: Dockerfile.llm
    ports:
      - "8001:8001"
    environment:
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - DATABASE_URL=${DATABASE_URL}
      - LOG_LEVEL=INFO
    volumes:
      - ./llm_microservice.py:/app/llm_microservice.py
      - ./llm_service.py:/app/llm_service.py
      - ./config.py:/app/config.py
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

networks:
  default:
    name: uw-workbench-network